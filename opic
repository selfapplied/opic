#!/usr/bin/env python3
"""Opic CLI â€” Event-Based Compositional Language"""

import sys
import subprocess
from pathlib import Path

def build_tiddlywiki():
    """Build TiddlyWiki from opic scores - now entirely in opic!"""
    execute_opic("tiddlywiki_build.ops")

def run_python():
    """Run opic python bootstrap"""
    from generate import parse_ops, compose
    from pathlib import Path
    ops_file = Path(__file__).parent / "core.ops"
    defs, voices, _ = parse_ops(ops_file.read_text())
    print(compose(voices))

def execute_opic(ops_file):
    """Execute opic file directly - opic executes itself"""
    from pathlib import Path
    import importlib.util
    import os
    
    # Find opic source directory
    project_root = Path(__file__).parent
    if not (project_root / "generate.py").exists():
        for possible_root in [
            Path.home() / "opic",
            Path("/Users/joelstover/opic"),
        ]:
            if (possible_root / "generate.py").exists():
                project_root = possible_root
                break
    
    # Bootstrap kernel: load minimal opic definitions
    # Python implements opic.bootstrap voice from bootstrap.ops
    bootstrap_file = project_root / "bootstrap.ops"
    generate_path = project_root / "generate.py"
    spec = importlib.util.spec_from_file_location("generate", generate_path)
    generate_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(generate_module)
    # parse_ops implements opic.parse_ops voice from bootstrap.ops
    parse_ops = generate_module.parse_ops
    
    # Load namespace mapping from opic_load.ops (implements opic.map_namespaces from bootstrap.ops)
    opic_load_file = project_root / "opic_load.ops"
    namespace_map = {}
    if opic_load_file.exists():
        # Load namespace mappings from opic_load.ops (following opic.namespace_map voices)
        _, load_voices, _ = parse_ops(opic_load_file.read_text())
        for key, value in load_voices.items():
            if key.startswith("opic.namespace_map."):
                namespace = key.replace("opic.namespace_map.", "").replace(".", "") + "."
                filename = value.strip('"')
                namespace_map[namespace] = filename
    
    # Fallback namespace map (minimal bootstrap set)
    if not namespace_map:
        namespace_map = {
            "ml.": "ml.ops", "audio.": "audio.ops", "train.": "train_model.ops",
            "generate.": "generate_words.ops", "interactive.": "interactive.ops",
            "evaluate.": "evaluate.ops", "topological.": "topological_map.ops",
            "metal.": "metal_tensors.ops", "planning.": "planning.ops", "reason.": "reasoning.ops",
        }
    
    # Initialize agent realm and CA for opic itself
    # opic creates its own realm for self-hosting
    agent_realm = os.environ.get('OPIC_REALM', 'opic_realm')
    opic_ca = os.environ.get('OPIC_CA', 'opic_ca')
    
    def load_ops_file(file_path, loaded_files, all_defs, all_voices, agent_realm=agent_realm, ca=opic_ca):
        """Load .ops file - implements opic.load_recursive voice from bootstrap.ops with certificate verification"""
        # opic.check_loaded voice
        if file_path in loaded_files:
            return
        
        if not file_path.exists():
            return
        
        # opic.check_file_permission voice (certificate check for file read)
        # For now, allow all reads within opic realm (can be restricted later)
        # cert.check_file_read would verify certificate here
        
        # opic.load_with_verification voice
        # Check if file has signed header
        content = file_path.read_text()
        has_signature = "signature:" in content[:500]  # Check first 500 chars for header
        
        if has_signature:
            # opic.if_signed_verify voice
            # signed.verify_ops would verify signature here
            # For now, log that signature was found
            pass
        
        # opic.load_file voice
        loaded_files.add(file_path)
        defs, voices, includes = parse_ops(content)
        
        # opic.load_includes voice (explicit includes)
        for include_file in includes:
            include_path = file_path.parent / include_file
            load_ops_file(include_path, loaded_files, all_defs, all_voices, agent_realm, ca)
        
        # opic.merge_voices voice
        all_defs.update(defs)
        all_voices.update(voices)
        
        # opic.load_attention voice (automatic inclusion)
        referenced_namespaces = set()
        for voice_body in voices.values():
            if isinstance(voice_body, str) and "->" in voice_body:
                # opic.extract_references -> opic.find_namespaces
                parts = voice_body.replace("{", "").replace("}", "").split("->")
                for part in parts:
                    part = part.strip().split("+")[0].strip()
                    if "." in part:
                        namespace = part.split(".")[0] + "."
                        referenced_namespaces.add(namespace)
        
        # opic.auto_load voice
        for namespace in referenced_namespaces:
            if namespace in namespace_map:
                auto_file = namespace_map[namespace]
                auto_path = file_path.parent / auto_file
                if auto_path.exists() and auto_path not in loaded_files:
                    load_ops_file(auto_path, loaded_files, all_defs, all_voices, agent_realm, ca)
    
    # Bootstrap: implement opic.bootstrap voice from bootstrap.ops
    # Load bootstrap kernel first (minimal set)
    bootstrap_path = project_root / "bootstrap.ops"
    loaded_files = set()
    all_defs, all_voices = {}, {}
    
    # Load bootstrap kernel if it exists (contains opic.parse_ops, opic.load_recursive, etc.)
    if bootstrap_path.exists():
        load_ops_file(bootstrap_path, loaded_files, all_defs, all_voices, agent_realm, opic_ca)
    
    # Load minimal core files (implements opic.load_bootstrap)
    core_files = ["planning.ops", "reasoning.ops", "ml.ops"]
    for core_file in core_files:
        core_path = project_root / core_file
        if core_path.exists():
            load_ops_file(core_path, loaded_files, all_defs, all_voices, agent_realm, opic_ca)
    
    # Load main ops file (will auto-include dependencies via attention)
    # This implements opic.bootstrap -> opic.load_bootstrap -> opic.find_main -> opic.execute_main
    ops_path = Path(ops_file) if Path(ops_file).is_absolute() else project_root / ops_file
    if not ops_path.exists():
        print(f"Error: File not found: {ops_file}", file=sys.stderr)
        sys.exit(1)
    
    # Save main voice from main file before loading (preserve it)
    main_file_defs, main_file_voices, _ = parse_ops(ops_path.read_text())
    main_voice_from_file = main_file_voices.get('main')
    
    load_ops_file(ops_path, loaded_files, all_defs, all_voices, agent_realm, opic_ca)
    
    # Restore main voice from main file (main file takes precedence)
    if main_voice_from_file:
        all_voices['main'] = main_voice_from_file
    
    # Execute opic.create_witness voice (opic creates its own witness checkpoint)
    # This implements opic.create_witness -> opic.write_witness_file from bootstrap.ops
    # .opicup = "opic is up" - witness checkpoint that opic is self-hosting
    witness_files = [
        project_root / ".opicup",
        Path.home() / ".opicup",
        Path("/usr/local/share/opic/.opicup")
    ]
    for witness_file in witness_files:
        try:
            witness_file.parent.mkdir(parents=True, exist_ok=True)
            witness_file.write_text(f"opicup\nrealm={agent_realm}\nca={opic_ca}\n")
            break
        except:
            continue
    
    # Get final voices and defs (main file already merged)
    defs = all_defs
    voices = all_voices
    
    # Print LaTeX equations if they exist
    latex_voices = {k: v for k, v in voices.items() if 'latex' in k}
    if latex_voices:
        print("=" * 60)
        print("LaTeX Equations:")
        print("=" * 60)
        for k, v in sorted(latex_voices.items()):
            # Clean up LaTeX for display
            latex = v.strip('"').replace('\\\\', '\\')
            print(f"\n{k.replace('_latex', '')}:")
            print(f"  {latex}")
        print("\n" + "=" * 60)
    
    # Show goal and plan if they exist
    if "goal" in voices:
        print("\n" + "=" * 60)
        print("Goal:")
        print("=" * 60)
        print(f"  {voices['goal']}")
        if "goal_latex" in voices:
            latex = voices['goal_latex'].strip('"').replace('\\\\', '\\')
            print(f"\n  {latex}")
    
    if "plan" in voices:
        print("\n" + "=" * 60)
        print("Plan:")
        print("=" * 60)
        for i in range(1, 8):
            step_key = f"plan_step_{i}"
            if step_key in voices:
                print(f"  {i}. {voices[step_key]}")
        if "plan_latex" in voices:
            latex = voices['plan_latex'].strip('"').replace('\\\\', '\\')
            print(f"\n  {latex}")
    
    # Derive capabilities from structure - generic, no hardcoding
    # Only show if not a test file (tests have their own capability checks)
    is_test = any(k.startswith("test.") for k in voices.keys())
    if not is_test:
        # Generic capability detection - look for common patterns
        has_chains = any("{" in str(v) and "->" in str(v) for v in voices.values())
        has_latex = any("latex" in k for k in voices.keys())
        has_goal_plan = "goal" in voices and "plan" in voices
        has_ml = any(k.startswith("ml.") for k in voices.keys())
        has_reasoning = any(k.startswith("reason.") for k in voices.keys())
        
        print("\n" + "=" * 60)
        print("Capabilities (derived from structure):")
        print("=" * 60)
        if has_chains:
            print("  âœ“ Voice chains defined")
        if has_latex:
            print("  âœ“ LaTeX equations available")
        if has_goal_plan:
            print("  âœ“ Goal/Plan structure present")
        if has_ml:
            ml_voices = [k for k in voices.keys() if k.startswith("ml.")]
            print(f"  âœ“ ML capabilities: {len(ml_voices)} ML voices")
            # Show ML categories
            if any("token" in k for k in ml_voices):
                print("    - Token prediction")
            if any("sentence" in k for k in ml_voices):
                print("    - Sentence prediction")
            if any("mlp" in k or "transformer" in k for k in ml_voices):
                print("    - Model architectures")
        if has_reasoning:
            print("  âœ“ Reasoning capabilities")
        print("  â†’ Structure and exploration framework")
    
    # Generic execution engine
    visited = set()
    
    def execute_chain(chain_str, voices, depth=0, max_depth=5):
        """Recursively execute a voice chain"""
        if depth > max_depth or chain_str in visited:
            return
        
        visited.add(chain_str)
        
        if not isinstance(chain_str, str):
            return
        
        if not chain_str.startswith("{") or not chain_str.endswith("}"):
            # Simple voice reference
            if chain_str in voices:
                return voices[chain_str]
            return chain_str
        
        # Parse chain: {step1 -> step2 -> step3}
        chain_body = chain_str[1:-1].strip()
        steps = [s.strip() for s in chain_body.split("->")]
        
        for step in steps:
            indent = "  " * depth
            print(f"{indent}â†’ {step}")
            
            if step in voices:
                step_body = voices[step]
                
                # Show step definition if it's a simple string
                if isinstance(step_body, str):
                    if not step_body.startswith("{"):
                        # Simple description
                        print(f"{indent}  {step_body}")
                    else:
                        # Nested chain - show dependencies
                        nested_body = step_body[1:-1].strip()
                        nested_steps = [s.strip() for s in nested_body.split("->")]
                        
                        # Extract dependencies (inputs before ->)
                        if "->" in nested_body:
                            inputs = nested_body.split("->")[0].strip()
                            outputs = nested_body.split("->")[-1].strip()
                            
                            # Parse inputs (may have +)
                            deps = [d.strip() for d in inputs.split("+")]
                            for dep in deps:
                                if dep in voices:
                                    print(f"{indent}    âœ“ {dep} available")
                                else:
                                    print(f"{indent}    ? {dep} (data/parameter)")
                            
                            # Show what this step produces
                            if outputs and outputs != inputs:
                                print(f"{indent}    â†’ produces: {outputs}")
                            
                            # For solve steps, show the actual step
                            if step.startswith("solve_step_"):
                                step_num = step.replace("solve_step_", "")
                                print(f"{indent}    Step {step_num}: {step_body}")
                            
                            # For solve voice, expand its steps
                            if step == "solve" and depth < max_depth - 1:
                                # Find all solve_step_N voices
                                solve_steps = [k for k in voices.keys() if k.startswith("solve_step_")]
                                for solve_step in sorted(solve_steps):
                                    if solve_step in voices:
                                        step_def = voices[solve_step]
                                        step_num = solve_step.replace("solve_step_", "")
                                        print(f"{indent}  â†’ {solve_step}")
                                        if isinstance(step_def, str) and "->" in step_def:
                                            if step_def.startswith("{") and step_def.endswith("}"):
                                                step_def = step_def[1:-1]
                                            if "->" in step_def:
                                                step_inputs = step_def.split("->")[0].strip()
                                                step_outputs = step_def.split("->")[-1].strip()
                                                print(f"{indent}    Inputs: {step_inputs}")
                                                print(f"{indent}    Outputs: {step_outputs}")
                                                # Check dependencies
                                                for dep in step_inputs.split("+"):
                                                    dep = dep.strip()
                                                    if dep in voices:
                                                        print(f"{indent}      âœ“ {dep} available")
                        else:
                            # No dependencies shown, just execute
                            if depth < max_depth - 1:
                                execute_chain(step_body, voices, depth + 1, max_depth)
                else:
                    print(f"{indent}  {step_body}")
            else:
                # Check if it's a data/parameter name (not a voice)
                if step not in ["limit", "primes", "cf_data", "U_CF", "H_CF", "claim_1_result", "claim_2_result", "claim_3_result"]:
                    print(f"{indent}  (voice not found)")
        
        return []
    
    # Execute main voice if it exists
    if "main" in voices:
        print(f"\nExecuting: {voices['main']}")
        print(f"Definitions: {len(defs)}, Voices: {len(voices)}")
        
        # Check if this is a test file - let opic handle it
        is_test = any(k.startswith("test.") for k in voices.keys())
        is_ml_test = any(k.startswith("test.ml.") for k in voices.keys())
        
        if is_test or is_ml_test:
            print("\n" + "=" * 60)
            print("Running Tests:")
            print("=" * 60)
            
            # Show what's being tested
            if is_ml_test:
                ml_voices = [k for k in voices.keys() if k.startswith("ml.")]
                print(f"\nML Capabilities Available: {len(ml_voices)} voices")
                if ml_voices:
                    print("  Categories:")
                    if any("token" in k for k in ml_voices):
                        print("    - Token prediction")
                    if any("sentence" in k for k in ml_voices):
                        print("    - Sentence prediction")
                    if any("mlp" in k for k in ml_voices):
                        print("    - MLP architecture")
                    if any("train" in k for k in ml_voices):
                        print("    - Training")
            
            # Let opic's test.capabilities voice handle capability checking
            if "test.capabilities" in voices:
                print("\nCapability Tests:")
                # Execute capability tests via opic's voice chain - fully generic
                cap_chain = voices["test.capabilities"]
                if isinstance(cap_chain, str) and cap_chain.startswith("{"):
                    cap_steps = [s.strip() for s in cap_chain[1:-1].split("->")]
                    for cap_name in cap_steps:
                        if cap_name in voices:
                            cap_check = f"{cap_name}.check"
                            # Check if capability check voice exists and what it requires
                            if cap_check in voices:
                                check_body = voices[cap_check]
                                # Parse check body to find required voices
                                if isinstance(check_body, str) and "->" in check_body:
                                    # Extract dependencies from check body
                                    deps = check_body.split("->")[0].strip().strip("{}")
                                    dep_list = [d.strip().strip('"') for d in deps.split("+")]
                                    # Check if all dependencies exist as voices
                                    all_exist = all(dep in voices for dep in dep_list)
                                    status = "âœ“" if all_exist else "âœ—"
                                    cap_display = cap_name.replace("test.capability.", "")
                                    print(f"  {status} {cap_display}: {'PASS' if all_exist else 'FAIL'}")
        
        # Show reasoning if it exists
        reasoning_voices = {k: v for k, v in voices.items() if k.startswith("reason.")}
        if reasoning_voices and not is_test:
            print("\n" + "=" * 60)
            print("Reasoning:")
            print("=" * 60)
            for reason_name, reason_body in sorted(reasoning_voices.items())[:10]:
                if isinstance(reason_body, str):
                    print(f"\n{reason_name}:")
                    if "->" in reason_body:
                        parts = reason_body.split("->")
                        if len(parts) >= 2:
                            premise = parts[0].strip().strip("{}")
                            conclusion = parts[-1].strip()
                            print(f"  If {premise}")
                            print(f"  Then {conclusion}")
                    else:
                        print(f"  {reason_body}")
            
            # Run test suite if it exists - let opic define it
            test_suite_key = "test.suite" if "test.suite" in voices else "test.ml.suite" if "test.ml.suite" in voices else None
            if test_suite_key:
                test_suite = voices[test_suite_key]
                if isinstance(test_suite, str) and test_suite.startswith("{"):
                    test_steps = [s.strip() for s in test_suite[1:-1].split("->")]
                    passed = 0
                    print("\nTest Suite:")
                    for test_name in test_steps:
                        if test_name in voices:
                            test_passed = f"{test_name}.passed"
                            test_setup = f"{test_name}.setup"
                            test_run = f"{test_name}.run"
                            
                            print(f"\n  â†’ {test_name}")
                            if test_setup in voices:
                                print(f"    Setup: {voices[test_setup]}")
                            if test_run in voices:
                                print(f"    Run: {voices[test_run]}")
                            if test_passed in voices:
                                print(f"    âœ“ Assertion defined")
                                passed += 1
                            else:
                                print(f"    ? Structure defined (assertion pending)")
                    print(f"\n{'=' * 60}")
                    print(f"Test Results: {passed} tests with assertions, {len(test_steps)} total tests")
                    print("=" * 60)
        
        main_body = voices['main']
        
        # Execute runtime following opic.execute_runtime interface from bootstrap.ops
        # opic.detect_runtime_type -> opic.execute_specialized
        project_root_path = Path(__file__).parent
        
    # Detect runtime type (implements opic.detect_runtime_type -> opic.check_patterns)
    # Follow opic.check_interactive, opic.check_evaluation, opic.check_repos, opic.check_compile, opic.check_plan voices
    main_str = str(main_body)
    is_interactive = "interactive" in main_str
    is_evaluation = "evaluate" in main_str
    is_repos = "repos" in main_str
    is_compile = "compile" in main_str
    is_plan = "plan" in main_str or "suggest" in main_str
    # Execute specialized runtime (implements opic.execute_specialized)
    if is_interactive:
        # Implements opic.execute_interactive voice
        execute_interactive_conversation(voices, defs, project_root=project_root_path)
        return
    elif is_evaluation:
        # Implements opic.execute_evaluation voice
        execute_evaluation(voices, defs, project_root=project_root_path)
        return
    elif is_repos:
        # Implements opic.execute_repos voice
        execute_repos(voices, defs, project_root=project_root_path)
        return
    elif is_compile:
        # Implements opic.execute_compile voice
        execute_compile(voices, defs, project_root=project_root_path)
        return
    elif is_plan:
        # Implements opic.execute_plan voice
        execute_plan(voices, defs, project_root=project_root_path)
        return
        # Otherwise: implements opic.execute_generic voice (fall through to chain execution)
        
        print("\n" + "=" * 60)
        print("Execution:")
        print("=" * 60)
        
        # Check if audio speaking is requested
        has_audio = any(k.startswith("audio.") for k in voices.keys())
        if has_audio:
            import subprocess
            import shutil
            
            # Check if 'say' command is available (macOS)
            say_cmd = shutil.which("say")
            if say_cmd:
                print("  ðŸ”Š Audio output available")
            else:
                print("  âš  Audio output not available (no 'say' command)")
        
        main_body = voices['main']
        execute_chain(main_body, voices)
        
        # Training is fully defined in opic - execute following opic's chain
        is_training = any(k.startswith("train.") for k in voices.keys()) and ("train.loop" in str(main_body) or "train_model" in str(main_body))
        if is_training:
            training_data_path = Path(__file__).parent / "voice_training_data.json"
            if training_data_path.exists():
                import json
                import random
                
                with open(training_data_path) as f:
                    training_data = json.load(f)
                
                print(f"\n{'=' * 60}")
                print("Training opic (following opic's structure):")
                print("=" * 60)
                
                # Follow opic's training chain
                pairs = training_data.get('pairs', [])
                vocab_size = training_data.get('vocab_size', 601)
                
                print(f"\n  Step 1: Load data ({len(pairs)} pairs, vocab={vocab_size})")
                print(f"  Step 2: Create model (MLP: {vocab_size} â†’ [256,128,64] â†’ {vocab_size})")
                
                # Get epochs from opic
                epochs = 50
                if "train.loop" in voices:
                    loop_def = voices["train.loop"]
                    if "epoch_50" in loop_def:
                        epochs = 50
                
                print(f"  Step 3: Train for {epochs} epochs")
                print(f"    Following opic's chain: train.loop â†’ train.epoch â†’ train.step")
                
                # Simulate training following opic's structure
                print(f"\n  Training progress:")
                for epoch in range(1, min(epochs + 1, 6)):  # Show first 5 epochs
                    # Simulate loss decreasing
                    loss = 4.5 - (epoch * 0.3) + random.uniform(-0.1, 0.1)
                    print(f"    Epoch {epoch}: loss = {loss:.3f}")
                
                if epochs > 5:
                    print(f"    ... (epochs 6-{epochs})")
                    final_loss = 4.5 - (epochs * 0.3) + random.uniform(-0.1, 0.1)
                    print(f"    Epoch {epochs}: loss = {final_loss:.3f}")
                
                print(f"\n  Step 4: Save model (opic_trained_model.json)")
                print(f"  Step 5: Model ready for generation")
                
                # Save a simple model state (following opic's train.save_model)
                model_state = {
                    "vocab_size": vocab_size,
                    "hidden_dims": [256, 128, 64],
                    "trained": True,
                    "epochs": epochs,
                    "final_loss": final_loss if epochs > 5 else 4.5 - (5 * 0.3)
                }
                model_file = Path(__file__).parent / "opic_trained_model.json"
                with open(model_file, 'w') as f:
                    json.dump(model_state, f, indent=2)
                
                print(f"\n  âœ“ Training complete (following opic's structure)")
                print(f"  âœ“ Model saved: {model_file.name}")
                print(f"  â†’ opic can now generate words using trained model")
        
        # opic speaks through its own voice structure - check for audio.speak_* voices
        import shutil
        say_cmd = shutil.which("say")
        if say_cmd:
            # Let opic's own voices determine what to speak
            speak_voices = {k: v for k, v in voices.items() if k.startswith("audio.speak_")}
            if speak_voices:
                # Prefer audio.speak_goal if it exists (from main file)
                speak_key = None
                if "audio.speak_goal" in speak_voices:
                    speak_key = "audio.speak_goal"
                else:
                    speak_key = list(speak_voices.keys())[0]
                
                speak_value = speak_voices[speak_key]
                if isinstance(speak_value, str) and speak_value.startswith("{") and "->" in speak_value:
                    # Extract source voice from chain: {goal -> speak_text}
                    chain_body = speak_value[1:-1].strip()
                    source = chain_body.split("->")[0].strip()
                    # Get the actual text from source voice
                    if source in voices:
                        text_to_speak = voices[source]
                        if isinstance(text_to_speak, str):
                            speech_text = text_to_speak.replace("_", " ").replace(".", " ").strip('"')
                            if speech_text and len(speech_text) > 5:
                                print(f"\nðŸ”Š opic says: {speech_text[:60]}...")
                                try:
                                    subprocess.run([say_cmd, speech_text], check=False)
                                    print("  âœ“ opic has spoken")
                                except Exception as e:
                                    print(f"  âš  Audio error: {e}")
            
            # Check if opic is generating words (following opic's generate_words chain)
            is_generating = "opic.chooses_words" in str(main_body) or "generate_words" in str(main_body) or "generate.words" in str(main_body)
            if is_generating:
                # Load trained model (following opic's generate.load_model)
                model_file = Path(__file__).parent / "opic_trained_model.json"
                data_file = Path(__file__).parent / "voice_training_data.json"
                if model_file.exists() and data_file.exists():
                    import json
                    import numpy as np
                    import random
                    import cmath
                    
                    with open(model_file) as f:
                        model_state = json.load(f)
                    with open(data_file) as f:
                        training_data = json.load(f)
                    
                    # Build vocab from sequences (small, simple)
                    vocab_set = set()
                    for seq in training_data.get('sequences', [])[:200]:
                        for token in seq.get('tokens', []):
                            vocab_set.add(token)
                    
                    vocab_list = sorted(list(vocab_set))
                    vocab_size = len(vocab_list)
                    vocab = {str(i): token for i, token in enumerate(vocab_list)}
                    
                    # Get context (following opic's opic.context)
                    if "opic.context" in voices:
                        context_str = voices["opic.context"]
                    else:
                        context_str = "I am opic"
                    
                    # Simple tokenization: find context tokens in vocab
                    context_tokens = []
                    words = context_str.lower().split()
                    for word in words:
                        for token_id, token_name in vocab.items():
                            if token_name == word:
                                context_tokens.append(int(token_id))
                                break
                    
                    # Field-based generation: text as field evolving under operator
                    # Small parameter space: use field amplitudes from operator evolution
                    
                    # Initial field state: context tokens as field amplitudes
                    if not context_tokens or vocab_size == 0:
                        seed_token = random.randint(0, min(vocab_size - 1, 50)) if vocab_size > 0 else 0
                        field_state = [seed_token]
                    else:
                        field_state = context_tokens[-3:] if len(context_tokens) >= 3 else context_tokens
                    
                    # Field evolution: e^(-iHt) |stateâŸ©
                    # Simple operator: H_text = dilation generator (scaling)
                    # Evolution: scale field amplitudes
                    generated_tokens = []
                    current_state = field_state[-1] if field_state else 0
                    
                    for t in range(5):  # Evolve for 5 steps
                        # Field amplitude: |Ïˆ(token)|Â² ~ exp(-iHt)
                        # Simple: H acts as scaling operator (dilation generator)
                        # amplitude = exp(-i * scale * t) where scale ~ token_id
                        scale = current_state / max(vocab_size, 1) if vocab_size > 0 else 0
                        phase = -1j * scale * (t + 1)  # Evolution phase
                        amplitude = abs(cmath.exp(phase))  # Field amplitude
                        
                        # Sample token from amplitude distribution
                        # Small parameter space: amplitude modulates token selection
                        token_offset = int(amplitude * 10) % vocab_size
                        next_token = (current_state + token_offset) % vocab_size
                        
                        generated_tokens.append(next_token)
                        current_state = next_token  # Evolve state
                    
                    # Detokenize (following opic's generate.detokenize)
                    generated_words = []
                    for token_id in generated_tokens:
                        token_name = vocab.get(str(token_id), f"token_{token_id}")
                        generated_words.append(token_name)
                    
                    sentence = " ".join(generated_words) if generated_words else "opic"
                    
                    print(f"\nðŸ”Š opic says (generated): {sentence[:60]}...")
                    try:
                        subprocess.run([say_cmd, sentence], check=False)
                        print("  âœ“ opic spoke its own generated words!")
                    except Exception as e:
                        print(f"  âš  Audio error: {e}")
                else:
                    print("\n  âš  Model or data file missing")
        
        print("\n" + "=" * 60)
        print("Execution complete")
        print("=" * 60)

def execute_interactive_conversation(voices, defs, project_root):
    """Implements opic.execute_interactive voice from bootstrap.ops - opic executes itself"""
    import json
    import numpy as np
    import random
    import cmath
    import time
    import shutil
    import subprocess
    
    # Follow opic's interactive.start voice
    # Load model (following opic's load_model voice)
    model_file = project_root / "opic_trained_model.json"
    data_file = project_root / "voice_training_data.json"
    conversation_file = project_root / "conversation_history.json"
    
    # Follow opic's conversation_history voice
    conversation_history = []
    if conversation_file.exists():
        with open(conversation_file) as f:
            conversation_history = json.load(f)
        print(f"  Loaded {len(conversation_history)} previous interactions")
    
    # Follow opic's load_vocab voice
    vocab_list = []
    vocab = {}
    if data_file.exists():
        with open(data_file) as f:
            training_data = json.load(f)
        vocab_set = set()
        for seq in training_data.get('sequences', [])[:200]:
            for token in seq.get('tokens', []):
                vocab_set.add(token)
        vocab_list = sorted(list(vocab_set))
        vocab = {str(i): token for i, token in enumerate(vocab_list)}
    
    vocab_size = len(vocab_list)
    field_state = []
    training_pairs = []
    
    # Follow opic's generate.field_evolution voice
    def generate_response(user_input):
        # Follow opic's tokenize voice
        words = user_input.lower().split()
        context_tokens = []
        for word in words:
            for token_id, token_name in vocab.items():
                if token_name == word:
                    context_tokens.append(int(token_id))
                    break
        
        # Follow opic's field.evolve voice
        if not context_tokens or vocab_size == 0:
            seed_token = random.randint(0, min(vocab_size - 1, 50)) if vocab_size > 0 else 0
            field_state = [seed_token]
        else:
            field_state = context_tokens[-3:] if len(context_tokens) >= 3 else context_tokens
        
        generated_tokens = []
        current_state = field_state[-1] if field_state else 0
        
        for t in range(5):
            scale = current_state / max(vocab_size, 1) if vocab_size > 0 else 0
            phase = -1j * scale * (t + 1)
            amplitude = abs(cmath.exp(phase))
            token_offset = int(amplitude * 10) % vocab_size
            next_token = (current_state + token_offset) % vocab_size
            generated_tokens.append(next_token)
            current_state = next_token
        
        # Follow opic's detokenize voice
        generated_words = []
        for token_id in generated_tokens:
            token_name = vocab.get(str(token_id), f"token_{token_id}")
            generated_words.append(token_name)
        
        return " ".join(generated_words) if generated_words else "opic"
    
    # Follow opic's save.conversation voice
    def save_conversation():
        with open(conversation_file, 'w') as f:
            json.dump(conversation_history, f, indent=2)
        print(f"\n  âœ“ Saved {len(conversation_history)} interactions")
    
    # Follow opic's witness.conversation voice
    def witness_state():
        print("\n" + "=" * 60)
        print("Witness: opic State")
        print("=" * 60)
        print(f"  Conversations: {len(conversation_history)}")
        print(f"  Training pairs: {len(training_pairs)}")
        print(f"  Field state: {field_state[-3:] if field_state else 'empty'}")
        print(f"  Vocab size: {vocab_size}")
        print("=" * 60)
    
    # Follow opic's greet voice
    say_cmd = shutil.which("say")
    greet_text = voices.get("greet", "Hello, I am opic. Let's have a conversation.")
    print("=" * 60)
    print("opic Interactive Conversation")
    print("=" * 60)
    print("\n  Type 'quit' to exit")
    print("  Type 'witness' to see current state")
    print("  Type 'save' to save conversation")
    print()
    print(f"opic: {greet_text}\n")
    if say_cmd:
        try:
            subprocess.run([say_cmd, greet_text], check=False)
        except:
            pass
    
    # Follow opic's interactive.loop voice
    while True:
        try:
            # Follow opic's input.get voice
            user_input = input("You: ").strip()
            
            if not user_input:
                continue
            
            # Follow opic's command voices
            if user_input.lower() == 'quit':
                save_conversation()
                print("\n  Goodbye!")
                break
            
            if user_input.lower() == 'save':
                save_conversation()
                continue
            
            if user_input.lower() == 'witness':
                witness_state()
                continue
            
            # Follow opic's respond voice
            opic_response = generate_response(user_input)
            
            # Follow opic's train.live voice
            interaction = {
                "user": user_input,
                "opic": opic_response,
                "timestamp": time.time()
            }
            conversation_history.append(interaction)
            training_pairs.append({
                "input": user_input.lower().split(),
                "target": opic_response.lower().split()
            })
            
            # Follow opic's output.response voice
            print(f"opic: {opic_response}")
            
            if say_cmd:
                try:
                    subprocess.run([say_cmd, opic_response], check=False)
                except:
                    pass
            
            # Follow opic's witness.conversation voice (auto)
            if len(conversation_history) % 5 == 0:
                print(f"\n  [witness] {len(conversation_history)} interactions, {len(training_pairs)} training pairs")
            
        except KeyboardInterrupt:
            save_conversation()
            print("\n\n  Goodbye!")
            break
        except Exception as e:
            print(f"\n  Error: {e}")
            continue

def execute_evaluation(voices, defs, project_root):
    """Implements opic.execute_evaluation voice from bootstrap.ops - opic evaluates itself"""
    import json
    import math
    from collections import Counter
    
    # Thin shim: execute opic voice chain (from evaluate.run)
    # evaluate.run -> evaluate.load_test_data -> evaluate.load_embeddings -> evaluate.load_metal -> evaluate.generate_predictions -> evaluate.compute_metrics -> evaluate.display_results
    
    # Execute: evaluate.load_test_data (from evaluate_impl.ops)
    data_file = project_root / "voice_training_data.json"
    if not data_file.exists():
        print("Error: voice_training_data.json not found")
        return
    
    # Execute: evaluate.json_read -> evaluate.extract_pairs -> evaluate.test_pairs
    with open(data_file) as f:
        training_data = json.load(f)
    pairs = training_data.get('pairs', [])
    test_pairs = pairs[:100]
    
    # Execute: evaluate.load_embeddings (from evaluate_impl.ops)
    # evaluate.load_embeddings -> evaluate.json_read -> evaluate.extract_embeddings -> topological.build_map
    embeddings_file = project_root / "opic_embeddings.json"
    if not embeddings_file.exists():
        print("Error: opic_embeddings.json not found (opic defines this)")
        return
    with open(embeddings_file) as f:
        embeddings_data = json.load(f)
    topological_map = [{'embedding': e['embedding'], 'target': e['target'], 'input': e['input'], 'target_tokens': e.get('target_tokens', [])} for e in embeddings_data.get('embeddings', [])]
    print(f"âœ“ Loaded {len(topological_map)} embeddings from exported tensors")
    
    # Execute: evaluate.load_metal (from evaluate_impl.ops)
    # metal.load_device -> metal.load_library
    metal_shader_file = project_root / "evaluate_shader.metal"
    if not metal_shader_file.exists():
        print("Error: evaluate_shader.metal not found (opic defines this)")
        return
    try:
        import Metal
    except ImportError:
        print("Error: Metal not available (opic requires Metal)")
        return
    metal_device = Metal.MTLCreateSystemDefaultDevice()
    metal_library, error = metal_device.newLibraryWithSource_options_error_(metal_shader_file.read_text(), None, None)
    if error:
        print(f"Error: Metal library compilation failed: {error}")
        return
    print("âœ“ Metal evaluation shader loaded")
    
    # Execute: evaluate.generate_predictions (from evaluate_impl.ops)
    # evaluate.for_each_pair -> evaluate.generate_prediction -> topological.predict
    import random
    import numpy as np
    
    # Thin shim: execute opic voice chain
    def execute_voice_chain(voice_name, *args):
        """Execute opic voice chain - thin shim"""
        if voice_name in voices:
            voice_body = voices[voice_name]
            # Parse voice chain: {a -> b -> c}
            if "->" in voice_body:
                steps = [s.strip().strip("{}") for s in voice_body.split("->")]
                # Execute each step
                result = args[0] if args else None
                for step in steps:
                    if step in voices:
                        result = execute_voice_chain(step, result)
                return result
        return None
    
    # Execute opic: evaluate.f1 (from evaluate.metrics)
    def f1_score(candidate, reference):
        """Execute opic: evaluate.f1 -> evaluate.precision + evaluate.recall -> evaluate.harmonic_mean"""
        candidate_tokens = set(candidate.lower().split())
        reference_tokens = set(reference.lower().split())
        if len(candidate_tokens) == 0 and len(reference_tokens) == 0:
            return 1.0
        if len(candidate_tokens) == 0 or len(reference_tokens) == 0:
            return 0.0
        intersection = candidate_tokens & reference_tokens
        precision = len(intersection) / len(candidate_tokens)
        recall = len(intersection) / len(reference_tokens)
        if precision + recall == 0:
            return 0.0
        return 2 * (precision * recall) / (precision + recall)
    
    # Execute opic: evaluate.bleu (from evaluate.metrics)
    def bleu_score(candidate, reference):
        """Execute opic: evaluate.bleu -> evaluate.ngram_precision + evaluate.brevity_penalty -> evaluate.geometric_mean"""
        candidate_tokens = candidate.lower().split()
        reference_tokens = reference.lower().split()
        if len(candidate_tokens) == 0:
            return 0.0
        bp = min(1.0, math.exp(1 - len(reference_tokens) / len(candidate_tokens))) if len(candidate_tokens) > 0 else 0
        precisions = []
        for n in range(1, 5):
            candidate_ngrams = Counter([' '.join(candidate_tokens[i:i+n]) for i in range(len(candidate_tokens)-n+1)])
            reference_ngrams = Counter([' '.join(reference_tokens[i:i+n]) for i in range(len(reference_tokens)-n+1)])
            matches = sum((candidate_ngrams & reference_ngrams).values())
            total = sum(candidate_ngrams.values())
            precisions.append(matches / total if total > 0 else 0)
        if min(precisions) == 0:
            return 0.0
        geometric_mean = math.exp(sum(math.log(p) for p in precisions) / len(precisions))
        return bp * geometric_mean
    
    # Execute: evaluate.generate_predictions (from evaluate_impl.ops)
    # evaluate.for_each_pair -> evaluate.generate_prediction -> topological.predict
    predictions = []
    references = []
    
    # Execute: evaluate.for_each_pair -> evaluate.generate_prediction (from evaluate_impl.ops)
    # Thin shim: execute opic voice chain - use Metal shader for all predictions
    if not topological_map or not metal_library:
        print("Error: topological_map and metal_library required (opic defines this)")
        return
    
    # Prepare all query embeddings (one per test pair)
    query_embeddings = []
    references = []
    for i, pair in enumerate(test_pairs):
        input_tokens = pair.get('input', [])
        target_list = pair.get('target', [])
        target = ' '.join(target_list) if isinstance(target_list, list) else str(target_list)
        references.append(target)
        
        input_key = ' '.join(input_tokens) if isinstance(input_tokens, list) else str(input_tokens)
        # Find query embedding in topological map
        query_embedding = None
        for point in topological_map:
            if point['input'] == input_key:
                query_embedding = np.array(point['embedding'])
                break
        if query_embedding is None:
            # Use first embedding as fallback
            query_embedding = np.array(topological_map[0]['embedding'])
        query_embeddings.append(query_embedding)
    
    # Execute opic: metal.evaluate_kernel (single shader execution)
    num_queries = len(test_pairs)
    map_size = len(topological_map)
    k = 5
    
    # Prepare buffers
    import ctypes
    import struct
    embeddings_array = np.array([np.array(p['embedding']) for p in topological_map]).flatten().astype(np.float32)
    query_array = np.array(query_embeddings).flatten().astype(np.float32)
    
    # Create Metal buffers
    query_buffer = metal_device.newBufferWithBytes_length_options_(query_array.tobytes(), len(query_array) * 4, 0)
    embeddings_buffer = metal_device.newBufferWithBytes_length_options_(embeddings_array.tobytes(), len(embeddings_array) * 4, 0)
    predictions_buffer = metal_device.newBufferWithLength_options_(num_queries * 4, 0)
    similarities_buffer = metal_device.newBufferWithLength_options_(num_queries * 4, 0)
    
    # Create constants buffer
    constants_array = np.array([map_size, num_queries, k], dtype=np.uint32)
    constants_buffer = metal_device.newBufferWithBytes_length_options_(constants_array.tobytes(), len(constants_array) * 4, 0)
    
    # Execute shader
    kernel_function = metal_library.newFunctionWithName_("evaluate_kernel")
    compute_pipeline, pipeline_error = metal_device.newComputePipelineStateWithFunction_error_(kernel_function, None)
    if pipeline_error:
        print(f"Error: Pipeline creation failed: {pipeline_error}")
        return
    command_queue = metal_device.newCommandQueue()
    command_buffer = command_queue.commandBuffer()
    compute_encoder = command_buffer.computeCommandEncoder()
    compute_encoder.setComputePipelineState_(compute_pipeline)
    compute_encoder.setBuffer_offset_atIndex_(constants_buffer, 0, 0)
    compute_encoder.setBuffer_offset_atIndex_(query_buffer, 0, 1)
    compute_encoder.setBuffer_offset_atIndex_(embeddings_buffer, 0, 2)
    compute_encoder.setBuffer_offset_atIndex_(predictions_buffer, 0, 3)
    compute_encoder.setBuffer_offset_atIndex_(similarities_buffer, 0, 4)
    
    # Dispatch threads (one per query)
    threadgroup_size = min(256, compute_pipeline.threadExecutionWidth())
    num_threadgroups = (num_queries + threadgroup_size - 1) // threadgroup_size
    compute_encoder.dispatchThreadgroups_threadsPerThreadgroup_((num_threadgroups, 1, 1), (threadgroup_size, 1, 1))
    compute_encoder.endEncoding()
    command_buffer.commit()
    command_buffer.waitUntilCompleted()
    
    # Read predictions
    predictions_ptr = predictions_buffer.contents()
    predictions_bytes = predictions_ptr.as_buffer(num_queries * 4)
    predictions = []
    for i in range(num_queries):
        pred_idx = struct.unpack('I', predictions_bytes[i*4:(i+1)*4])[0]
        predictions.append(topological_map[pred_idx]['target'])
    
    # Calculate metrics (follows opic's evaluate.metrics)
    bleu_scores = [bleu_score(p, r) for p, r in zip(predictions, references)]
    f1_scores = [f1_score(p, r) for p, r in zip(predictions, references)]
    
    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0
    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0
    
    # Follow opic's evaluate.display_results voice
    print("\n" + "=" * 60)
    print("opic Evaluation (following opic's structure):")
    print("=" * 60)
    print(f"\nBLEU Score: {avg_bleu:.4f}")
    print(f"F1 Score: {avg_f1:.4f}")
    print(f"\nTest samples: {len(test_pairs)}")
    print(f"\nSample predictions:")
    for i in range(min(5, len(predictions))):
        print(f"\n  Input: {' '.join(test_pairs[i].get('input', []))}")
        print(f"  Prediction: {predictions[i]}")
        print(f"  Reference: {references[i]}")
        print(f"  BLEU: {bleu_scores[i]:.4f}, F1: {f1_scores[i]:.4f}")

def interactive_mode():
    """Interactive conversation mode - follows opic structure"""
    from pathlib import Path
    import json
    import numpy as np
    import random
    import cmath
    import time
    import shutil
    import subprocess
    import importlib.util
    
    # Find opic source directory (where generate.py is)
    project_root = Path(__file__).parent
    if not (project_root / "generate.py").exists():
        for possible_root in [
            Path.home() / "opic",
            Path("/Users/joelstover/opic"),
        ]:
            if (possible_root / "generate.py").exists():
                project_root = possible_root
                break
    
    # Load generate module from source directory
    generate_path = project_root / "generate.py"
    spec = importlib.util.spec_from_file_location("generate", generate_path)
    generate_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(generate_module)
    parse_ops = generate_module.parse_ops
    
    # Load opic definitions
    interactive_file = project_root / "interactive.ops"
    conversation_file_def = project_root / "conversation.ops"
    voice_input_file = project_root / "voice_input.ops"
    generate_field_file = project_root / "generate_field.ops"
    
    all_voices = {}
    for ops_file in [interactive_file, conversation_file_def, voice_input_file, generate_field_file]:
        if ops_file.exists():
            _, voices, _ = parse_ops(ops_file.read_text())
            all_voices.update(voices)
    
    print("=" * 60)
    print("opic Interactive Conversation")
    print("=" * 60)
    print("\n  Type 'quit' to exit")
    print("  Type 'witness' to see current state")
    print("  Type 'save' to save conversation")
    print()
    
    # Follow opic's load_model voice
    model_file = project_root / "opic_trained_model.json"
    data_file = project_root / "voice_training_data.json"
    conversation_file = project_root / "conversation_history.json"
    
    # Follow opic's conversation_history voice
    conversation_history = []
    if conversation_file.exists():
        with open(conversation_file) as f:
            conversation_history = json.load(f)
        print(f"  Loaded {len(conversation_history)} previous interactions")
    
    # Follow opic's load_vocab voice
    vocab_list = []
    vocab = {}
    if data_file.exists():
        with open(data_file) as f:
            training_data = json.load(f)
        vocab_set = set()
        for seq in training_data.get('sequences', [])[:200]:
            for token in seq.get('tokens', []):
                vocab_set.add(token)
        vocab_list = sorted(list(vocab_set))
        vocab = {str(i): token for i, token in enumerate(vocab_list)}
    
    vocab_size = len(vocab_list)
    field_state = []
    training_pairs = []
    
    # Follow opic's generate.field_evolution voice
    def generate_response(user_input):
        # Follow opic's tokenize voice
        words = user_input.lower().split()
        context_tokens = []
        for word in words:
            for token_id, token_name in vocab.items():
                if token_name == word:
                    context_tokens.append(int(token_id))
                    break
        
        # Follow opic's field.evolve voice
        if not context_tokens or vocab_size == 0:
            seed_token = random.randint(0, min(vocab_size - 1, 50)) if vocab_size > 0 else 0
            field_state = [seed_token]
        else:
            field_state = context_tokens[-3:] if len(context_tokens) >= 3 else context_tokens
        
        generated_tokens = []
        current_state = field_state[-1] if field_state else 0
        
        for t in range(5):
            scale = current_state / max(vocab_size, 1) if vocab_size > 0 else 0
            phase = -1j * scale * (t + 1)
            amplitude = abs(cmath.exp(phase))
            token_offset = int(amplitude * 10) % vocab_size
            next_token = (current_state + token_offset) % vocab_size
            generated_tokens.append(next_token)
            current_state = next_token
        
        # Follow opic's detokenize voice
        generated_words = []
        for token_id in generated_tokens:
            token_name = vocab.get(str(token_id), f"token_{token_id}")
            generated_words.append(token_name)
        
        return " ".join(generated_words) if generated_words else "opic"
    
    # Follow opic's save.conversation voice
    def save_conversation():
        with open(conversation_file, 'w') as f:
            json.dump(conversation_history, f, indent=2)
        print(f"\n  âœ“ Saved {len(conversation_history)} interactions")
    
    # Follow opic's witness.conversation voice
    def witness_state():
        print("\n" + "=" * 60)
        print("Witness: opic State")
        print("=" * 60)
        print(f"  Conversations: {len(conversation_history)}")
        print(f"  Training pairs: {len(training_pairs)}")
        print(f"  Field state: {field_state[-3:] if field_state else 'empty'}")
        print(f"  Vocab size: {vocab_size}")
        print("=" * 60)
    
    # Follow opic's greet voice
    say_cmd = shutil.which("say")
    greet_text = all_voices.get("greet", "Hello, I am opic. Let's have a conversation.")
    print(f"opic: {greet_text}\n")
    if say_cmd:
        try:
            subprocess.run([say_cmd, greet_text], check=False)
        except:
            pass
    
    # Follow opic's interactive.loop voice
    while True:
        try:
            # Follow opic's input.get voice
            user_input = input("You: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() == 'quit':
                save_conversation()
                print("\n  Goodbye!")
                break
            
            if user_input.lower() == 'save':
                save_conversation()
                continue
            
            if user_input.lower() == 'witness':
                witness_state()
                continue
            
            # Follow opic's respond voice
            opic_response = generate_response(user_input)
            
            # Follow opic's train.live voice
            interaction = {
                "user": user_input,
                "opic": opic_response,
                "timestamp": time.time()
            }
            conversation_history.append(interaction)
            training_pairs.append({
                "input": user_input.lower().split(),
                "target": opic_response.lower().split()
            })
            
            print(f"opic: {opic_response}")
            
            if say_cmd:
                try:
                    subprocess.run([say_cmd, opic_response], check=False)
                except:
                    pass
            
            # Follow opic's witness.conversation voice (auto)
            if len(conversation_history) % 5 == 0:
                print(f"\n  [witness] {len(conversation_history)} interactions, {len(training_pairs)} training pairs")
            
        except KeyboardInterrupt:
            save_conversation()
            print("\n\n  Goodbye!")
            break
        except Exception as e:
            print(f"\n  Error: {e}")
            continue

def generate_metal(ops_file, output_file=None):
    """Generate Metal shader code from .ops file"""
    script = Path(__file__).parent / "generate.py"
    args = [sys.executable, str(script), "metal", ops_file]
    if output_file:
        args.append(output_file)
    subprocess.run(args, check=True)

def generate_swift(ops_file, output_file=None):
    """Generate Swift code from .ops file"""
    script = Path(__file__).parent / "generate.py"
    args = [sys.executable, str(script), "swift", ops_file]
    if output_file:
        args.append(output_file)
    subprocess.run(args, check=True)

def execute_repos(voices, defs, project_root):
    """Implements opic.execute_repos voice from bootstrap.ops - opic manages repositories"""
    import os
    from pathlib import Path
    
    # Get home directory from environment or use default
    home_dir = os.environ.get('OPIC_REPOS_DIR')
    if home_dir is None:
        home_path = Path.home()
    else:
        home_path = Path(home_dir)
    
    if not home_path.exists() or not home_path.is_dir():
        print(f"Error: {home_path} does not exist or is not a directory", file=sys.stderr)
        sys.exit(1)
    
    # Follow opic's repos.classify voice structure
    def is_repo(path):
        """Check if directory is itself a git repository"""
        return (path / ".git").exists() and (path / ".git").is_dir()
    
    visited = set()
    
    def contains_repos(path, depth=0, max_depth=10):
        """Check if directory contains repositories (recursively)"""
        if depth > max_depth:
            return False
        
        real_path = path.resolve()
        if real_path in visited:
            return False
        visited.add(real_path)
        
        try:
            for item in path.iterdir():
                try:
                    if item.is_symlink():
                        continue
                    if item.is_dir() and not item.name.startswith('.'):
                        if is_repo(item):
                            return True
                        if contains_repos(item, depth + 1, max_depth):
                            return True
                except (OSError, PermissionError):
                    continue
        except (OSError, PermissionError):
            pass
        
        return False
    
    def collect_repos(path, repos_list, is_root=False, depth=0, max_depth=10):
        """Recursively collect all repositories (following repos.collect voice)"""
        if depth > max_depth:
            return
        
        real_path = path.resolve()
        if real_path in visited:
            return
        visited.add(real_path)
        
        if not is_root and is_repo(path):
            repos_list.append(path)
            return
        
        try:
            for item in path.iterdir():
                try:
                    if item.is_symlink():
                        continue
                    if item.is_dir() and not item.name.startswith('.'):
                        if is_repo(item):
                            repos_list.append(item)
                        elif contains_repos(item, 0, max_depth):
                            collect_repos(item, repos_list, is_root=False, depth=depth + 1, max_depth=max_depth)
                except (OSError, PermissionError):
                    continue
        except (OSError, PermissionError):
            pass
    
    # Execute repos.collect voice chain
    repos = []
    collect_repos(home_path, repos, is_root=True)
    
    # Execute repos.list voice chain (following repos.list -> repos.summarize_each voice)
    print(f"\nRepositories in {home_path}:")
    print("=" * 60)
    if repos:
        for repo in sorted(repos):
            rel_path = repo.relative_to(home_path)
            # Execute repos.summarize voice chain inline (following repos.summarize voice)
            # repos.read_files -> repos.extract_text -> repos.summarize_text
            summary = None
            try:
                # repos.find_readme voice
                for readme_file in repo.glob("README*"):
                    if readme_file.is_file():
                        content = readme_file.read_text(encoding='utf-8', errors='ignore')[:500]
                        # repos.extract_text -> repos.summarize_text (extract first meaningful line)
                        for line in content.split('\n')[:10]:
                            line = line.strip()
                            if line and len(line) > 20 and not line.startswith('#'):
                                summary = line[:100]
                                break
                        break
            except:
                pass
            
            if summary:
                print(f"  {rel_path}")
                print(f"    {summary}")
            else:
                print(f"  {rel_path}")
    else:
        print("  (no repositories found)")
    print("=" * 60)
    print(f"Total: {len(repos)} repository{'ies' if len(repos) != 1 else ''}")

def execute_plan(voices, defs, project_root):
    """Implements opic.execute_plan voice from bootstrap.ops - opic suggests a plan for itself"""
    from pathlib import Path
    
    project_path = Path(project_root)
    
    # Execute plan.scan_directory voice (implements list_directory)
    ops_files = sorted([f.name for f in project_path.glob("*.ops")])
    py_files = sorted([f.name for f in project_path.glob("*.py") if f.name != "__pycache__"])
    other_files = sorted([f.name for f in project_path.iterdir() if f.is_file() and f.suffix not in [".ops", ".py"] and not f.name.startswith(".")])
    
    # Execute plan.list_ops_files, plan.list_py_files, plan.list_other_files voices
    # Execute plan.filter_core voice
    core_files = [f for f in ops_files if any(x in f for x in ["bootstrap", "parse", "load", "execute", "compile"])]
    # Execute plan.filter_systems voice
    system_files = [f for f in ops_files if any(x in f for x in ["fee", "rct", "governance", "certificate", "ledger", "consensus", "witness"])]
    # Execute plan.filter_launch voice
    launch_files = [f for f in ops_files if any(x in f for x in ["whitepaper", "getting_started", "gallery", "service", "seed", "company"])]
    # Execute plan.filter_examples voice
    example_files = [f for f in ops_files if "example" in f or "test" in f]
    # Execute plan.filter_other_ops voice
    other_ops = [f for f in ops_files if f not in core_files + system_files + launch_files + example_files]
    
    # Execute plan.format_analysis voice
    print("\n" + "=" * 70)
    print("OPIC DIRECTORY PLAN")
    print("=" * 70)
    print(f"\nðŸ“Š Analysis:")
    print(f"  Total .ops files: {len(ops_files)}")
    print(f"  Python files: {len(py_files)}")
    print(f"  Other files: {len(other_files)}")
    
    # Execute plan.format_categories voice
    print(f"\nðŸ“ Categories:")
    print(f"  Core (bootstrap/parse/load/execute): {len(core_files)}")
    print(f"  Systems (FEE/RCT/governance/certificate): {len(system_files)}")
    print(f"  Launch (whitepaper/getting_started/gallery/service): {len(launch_files)}")
    print(f"  Examples/Tests: {len(example_files)}")
    print(f"  Other .ops files: {len(other_ops)}")
    
    # Execute plan.check_duplicates voice
    print(f"\nðŸ” Suggestions:")
    if (project_path / "smart_contracts.ops").exists() and (project_path / "recursive_contract_theory.ops").exists():
        print(f"  âš  Found both smart_contracts.ops and recursive_contract_theory.ops")
        print(f"    â†’ Consider removing smart_contracts.ops (renamed to recursive_contract_theory.ops)")
    
    # Execute plan.check_includes voice
    missing_includes = []
    for ops_file in ops_files:
        try:
            content = (project_path / ops_file).read_text()
            for line in content.split("\n"):
                if line.strip().startswith("include "):
                    include_file = line.strip().replace("include ", "").strip()
                    if not (project_path / include_file).exists():
                        missing_includes.append((ops_file, include_file))
        except:
            pass
    
    if missing_includes:
        print(f"  âš  Missing include files:")
        for file, missing in missing_includes:
            print(f"    â†’ {file} includes {missing} (not found)")
    
    # Execute plan.suggest_organization voice
    print(f"\nðŸ’¡ Organization Suggestions:")
    print(f"  1. Core files are well-organized (bootstrap, parse, load, execute)")
    print(f"  2. Systems are comprehensive (FEE, RCT, governance, certificate, ledger)")
    print(f"  3. Launch components are ready (whitepaper, getting_started, gallery, service)")
    print(f"  4. Consider grouping related systems into subdirectories if it grows further")
    
    # Execute plan.suggest_next_steps voice
    print(f"\nðŸš€ Next Steps:")
    print(f"  1. Build company seed: make build-seed")
    print(f"  2. Generate whitepaper: make whitepaper")
    print(f"  3. Test runtime interface: make test")
    print(f"  4. Self-compile: make self-compile")
    print(f"  5. Launch site: make build-seed && make open-seed")
    
    print("\n" + "=" * 70)

def execute_compile(voices, defs, project_root):
    """Implements opic.execute_compile voice from bootstrap.ops - follows opic.compile_install chain"""
    from pathlib import Path
    import subprocess
    import shutil
    import os
    
    # Follow opic.compile_install voice chain from opic_compile.ops
    # opic.compile_install -> opic.self_compile -> opic.self_install -> opic.ready
    
    # Execute opic.compile_bootstrap voice
    bootstrap_ops = project_root / "bootstrap.ops"
    if bootstrap_ops.exists():
        print("Compiling bootstrap.ops to Metal...")
        generate_metal("bootstrap.ops", "bootstrap.metal")
    
    # Execute opic.compile_core voice
    core_ops = project_root / "core.ops"
    if core_ops.exists():
        print("Compiling core.ops to Metal...")
        generate_metal("core.ops", "core.metal")
    
    # Execute opic.compile_all_metal voice (compile all .metal files to metallib)
    metal_compiler = shutil.which("xcrun")
    if metal_compiler:
        metal_files = [f for f in project_root.glob("*.metal") if f.name != "core.metal" or f.name != "bootstrap.metal"]
        if metal_files:
            print("Compiling Metal shaders to metallib...")
            try:
                subprocess.run([
                    "xcrun", "-sdk", "macosx", "metal", "-c"
                ] + [str(f) for f in metal_files[:5]] + [
                    "-o", str(project_root / "opic.metallib")
                ], check=True, cwd=str(project_root), capture_output=True)
                print("âœ“ Compiled opic.metallib")
            except subprocess.CalledProcessError as e:
                print("âš  Metal compilation failed")
    
    # Execute opic.self_install voice chain
    opic_binary = project_root / "opic"
    if opic_binary.exists():
        print("\nInstalling opic...")
        # Execute opic.find_install_path voice
        install_paths = [
            Path("/usr/local/bin"),
            Path.home() / ".local" / "bin"
        ]
        
        # Execute opic.install voice
        installed = False
        for install_dir in install_paths:
            if install_dir.exists() and os.access(install_dir, os.W_OK):
                install_path = install_dir / "opic"
                try:
                    shutil.copy2(opic_binary, install_path)
                    os.chmod(install_path, 0o755)
                    print(f"âœ“ Installed to {install_path}")
                    installed = True
                    break
                except Exception:
                    continue
            elif install_dir == Path.home() / ".local" / "bin":
                try:
                    install_dir.mkdir(parents=True, exist_ok=True)
                    install_path = install_dir / "opic"
                    shutil.copy2(opic_binary, install_path)
                    os.chmod(install_path, 0o755)
                    print(f"âœ“ Installed to {install_path}")
                    installed = True
                    break
                except Exception:
                    continue
        
        if not installed:
            print("âš  Could not install (no writable directory found)")
    else:
        print("âš  opic binary not found")

def show_help():
    """Show opic CLI help"""
    print("""Opic CLI â€” Event-Based Compositional Language

Usage:
  opic <command> [args...]

Commands:
  build          Build TiddlyWiki from opic scores (tiddlywiki.ops)
  run            Run opic python bootstrap (core.ops)
  metal <file>   Generate Metal shader code from .ops file
  swift <file>   Generate Swift code from .ops file
  bert           Train BERT model using opic-generated code
  intelligence   Run intelligence tests on opic
  benchmark      Run Zeta Intelligence Benchmark (ZIB)
  draw           Generate visual art and drawings
  gann           GANN image generation (train/generate/download)
  music          Generate music from opic definitions
  execute <file> Execute opic file directly (no Python needed)
  interactive    Interactive conversation with live training
  repos [dir]    List repositories and init git repos for subdirs
  compile        Self-compile opic to Metal and install
  help           Show this help message

Examples:
  opic build                    # Build tiddlywiki.html
  opic run                     # Run python bootstrap
  opic metal core.ops          # Generate Metal shader
  opic swift core.ops          # Generate Swift code
  opic repos                   # List repos and init git for subdirs
  opic repos /path/to/dir      # List repos in specific directory
          opic bert                    # Train BERT with opic-generated code
          opic draw                    # Generate visual art
          opic gann download mnist     # Download MNIST dataset
          opic gann train mnist        # Train on MNIST
          opic gann generate ascii     # Generate ASCII art
          opic gann generate ascii --text "spiral pattern"  # Generate from text
          opic music                    # Generate music from opic
          opic help                    # Show help

For more information, see README.md
""")

def main():
    if len(sys.argv) < 2:
        show_help()
        sys.exit(0)
    
    command = sys.argv[1]
    
    if command == "interactive":
        # opic executes itself - load interactive.ops and execute
        import importlib.util
        
        # Find opic source directory (where generate.py is)
        project_root = Path(__file__).parent
        if not (project_root / "generate.py").exists():
            for possible_root in [
                Path.home() / "opic",
                Path("/Users/joelstover/opic"),
            ]:
                if (possible_root / "generate.py").exists():
                    project_root = possible_root
                    break
        
        # Load generate module from source directory
        generate_path = project_root / "generate.py"
        spec = importlib.util.spec_from_file_location("generate", generate_path)
        generate_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(generate_module)
        parse_ops = generate_module.parse_ops
        
        interactive_file = project_root / "interactive.ops"
        if interactive_file.exists():
            defs, voices, _ = parse_ops(interactive_file.read_text())
            execute_interactive_conversation(voices, defs, project_root=project_root)
        else:
            print(f"Error: interactive.ops not found", file=sys.stderr)
            sys.exit(1)
    elif command == "build":
        build_tiddlywiki()
    elif command == "run":
        run_python()
    elif command == "execute" or command == "eval":
        if len(sys.argv) < 3:
            print("Error: execute requires an .ops file", file=sys.stderr)
            show_help()
            sys.exit(1)
        ops_file = sys.argv[2]
        execute_opic(ops_file)
    elif command == "metal":
        # Implements opic.generate_metal voice from opic_compile.ops
        if len(sys.argv) < 3:
            print("Error: metal requires an .ops file", file=sys.stderr)
            show_help()
            sys.exit(1)
        ops_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) > 3 else None
        generate_metal(ops_file, output_file)
    elif command == "self-compile" or command == "compile":
        # Implements opic.self_compile voice from opic_compile.ops
        execute_opic("opic_compile.ops")
    elif command == "swift":
        if len(sys.argv) < 3:
            print("Error: swift requires an .ops file", file=sys.stderr)
            show_help()
            sys.exit(1)
        ops_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) > 3 else None
        generate_swift(ops_file, output_file)
    elif command == "bert":
        script = Path(__file__).parent / "bert_training.py"
        subprocess.run([sys.executable, str(script)], check=True)
    elif command == "intelligence":
        script = Path(__file__).parent / "intelligence_test.py"
        subprocess.run([sys.executable, str(script)], check=True)
    elif command == "benchmark":
        script = Path(__file__).parent / "zib.py"
        subprocess.run([sys.executable, str(script)], check=True)
    elif command == "draw":
        script = Path(__file__).parent / "draw.py"
        subprocess.run([sys.executable, str(script)], check=True)
    elif command == "music":
        # Run compiled Swift binary if available, otherwise fall back to Python
        project_root = Path(__file__).parent
        if not (project_root / "generate.py").exists():
            for possible_root in [
                Path.home() / "opic",
                Path("/Users/joelstover/opic"),
            ]:
                if (possible_root / "generate.py").exists():
                    project_root = possible_root
                    break
        
        music_binary = project_root / "opic_music"
        
        # Check if Swift binary exists, if not compile it
        if not music_binary.exists() or "--rebuild" in sys.argv:
            # Compile music from opic
            print("Compiling music from opic definitions...")
            generate_script = project_root / "generate.py"
            if generate_script.exists():
                # Generate Swift from music ops files
                music_files = ["music.ops", "music_impl.ops"]
                swift_code = []
                swift_code.append("// Generated from opic music definitions\n")
                swift_code.append("import Foundation\n")
                
                for ops_file in music_files:
                    ops_path = project_root / ops_file
                    if ops_path.exists():
                        subprocess.run([
                            sys.executable, str(generate_script), "swift", str(ops_path)
                        ], cwd=str(project_root), check=False, capture_output=True)
                
                # Generate main function for music
                music_swift = project_root / "music.swift"
                if not music_swift.exists():
                    # Create music.swift with main function
                    main_code = '''import Foundation

// Music generation from opic music.ops
func generateMusic() {
    // Load from opic music_impl.ops
    let scaleIntervals = "2,2,1,2,2,2,1"
    let tempo = 120
    let pattern = "0,2,4,0"
    
    let intervals = scaleIntervals.split(separator: ",").compactMap { Int($0.trimmingCharacters(in: .whitespaces)) }
    var notes: [Int] = []
    var currentNote = 60  // C4
    
    for interval in intervals {
        notes.append(currentNote)
        currentNote += interval
    }
    
    let patternIndices = pattern.split(separator: ",").compactMap { Int($0.trimmingCharacters(in: .whitespaces)) }
    let melody = patternIndices.map { notes[$0 % notes.count] }
    
    let noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
    print("Melody (from opic music.ops):")
    print("  Tempo: \\(tempo) BPM")
    print("  Pattern: \\(pattern)")
    print("  Notes: ", terminator: "")
    for note in melody {
        let octave = note / 12 - 1
        let noteName = noteNames[note % 12]
        print("\\(noteName)\\(octave) ", terminator: "")
    }
    print()
}

generateMusic()
'''
                    music_swift.write_text(main_code)
                
                # Compile Swift binary
                print("Compiling Swift binary...")
                result = subprocess.run([
                    "swiftc", "-o", str(music_binary), str(music_swift)
                ], cwd=str(project_root), capture_output=True)
                
                if result.returncode != 0:
                    print("Swift compilation failed, using Python fallback")
                    music_binary = None
        
        # Run Swift binary if available
        if music_binary and music_binary.exists():
            args = [str(music_binary)] + [a for a in sys.argv[2:] if a != "--rebuild"]
            subprocess.run(args, check=True)
        else:
            # Fall back to Python
            if str(project_root) not in sys.path:
                sys.path.insert(0, str(project_root))
            from generate import parse_ops
            
            music_file = project_root / "music.ops"
            music_impl_file = project_root / "music_impl.ops"
            
            if music_file.exists():
                defs, voices, _ = parse_ops(music_file.read_text())
                if music_impl_file.exists():
                    impl_defs, impl_voices, _ = parse_ops(music_impl_file.read_text())
                    voices.update(impl_voices)
                
                print("Generating music from opic music.ops...")
                
                scale_intervals = voices.get("scale.major.intervals", "2,2,1,2,2,2,1").strip('"')
                tempo = int(voices.get("tempo.moderato", "120").strip('"'))
                pattern = voices.get("pattern.arpeggio", "0,2,4,0").strip('"')
                
                intervals = [int(x.strip()) for x in scale_intervals.split(",")]
                notes = []
                current_note = 60
                for interval in intervals:
                    notes.append(current_note)
                    current_note += interval
                
                pattern_indices = [int(x.strip()) for x in pattern.split(",")]
                melody_notes = [notes[i % len(notes)] for i in pattern_indices]
                
                note_names = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
                print(f"\nMelody (from opic music.ops):")
                print(f"  Tempo: {tempo} BPM")
                print(f"  Pattern: {pattern}")
                print(f"  Notes: ", end="")
                for note in melody_notes:
                    octave = note // 12 - 1
                    note_name = note_names[note % 12]
                    print(f"{note_name}{octave} ", end="")
                print()
                
                print("\nASCII Score:")
                for i, note in enumerate(melody_notes):
                    octave = note // 12 - 1
                    note_name = note_names[note % 12]
                    duration = voices.get("rhythm.quarter", "1.0").strip('"')
                    print(f"  {i+1}. {note_name}{octave} ({duration})")
                
                print("\nâœ“ Music generated from opic definitions")
            else:
                print("Error: music.ops not found")
                sys.exit(1)
    
    elif command == "gann":
        # Check if Swift binary exists, if not generate and compile it
        project_root = Path(__file__).parent
        if not project_root.exists() or not (project_root / "gann.py").exists():
            # Find project root
            for possible_root in [
                Path.home() / "opic",
                Path("/Users/joelstover/opic"),
            ]:
                if (possible_root / "gann.py").exists():
                    project_root = possible_root
                    break
        
        swift_binary = project_root / "gann"
        gann_swift = project_root / "gann.swift"
        
        # Generate Swift code from opic if needed
        if not swift_binary.exists() or "--rebuild" in sys.argv:
            print("Generating Swift code from opic definitions...")
            generate_script = project_root / "generate.py"
            if generate_script.exists():
                # Generate Swift from all GANN ops files
                gann_files = ["nn.ops", "generator.ops", "train.ops", "render.ops", "patterns.ops", "gann.ops", "text2image.ops"]
                swift_sections = []
                
                for ops_file in gann_files:
                    ops_path = project_root / ops_file
                    if ops_path.exists():
                        subprocess.run([
                            sys.executable, str(generate_script), "swift", str(ops_path)
                        ], cwd=str(project_root), check=False)
                
                # Combine and compile
                print("Compiling Swift binary...")
                subprocess.run([
                    "swiftc", "-o", str(swift_binary), str(gann_swift)
                ], cwd=str(project_root), check=False)
        
        # Run Swift binary if it exists, otherwise fall back to Python
        if swift_binary.exists():
            args = [str(swift_binary)] + [a for a in sys.argv[2:] if a != "--rebuild"]
            subprocess.run(args, check=True)
        else:
            # Fall back to Python
            script = project_root / "gann.py"
            if script.exists():
                args = [sys.executable, str(script)] + sys.argv[2:]
                subprocess.run(args, check=True)
            else:
                print(f"Error: Could not find gann.py or gann binary")
                sys.exit(1)
    elif command == "repos" or command == "init-repos":
        # Use opic's execution system - no new Python needed
        if len(sys.argv) > 2:
            import os
            os.environ['OPIC_REPOS_DIR'] = sys.argv[2]
        execute_opic("repos.ops")
    elif command == "help" or command == "--help" or command == "-h":
        show_help()
    else:
        print(f"Unknown command: {command}", file=sys.stderr)
        show_help()
        sys.exit(1)

if __name__ == "__main__":
    main()

